# 项目优化改进计划

> 基于代码审查的客观评估，按优先级排序。每项标注预计改动范围和风险。

---

## 第一阶段：安全与卫生（必须立即做）

### 1.1 清除硬编码密钥
**问题**：`config.py` 中硬编码了 3 个 DeepSeek API Key、PubMed 邮箱、2 个 PushPlus Token，推到 GitHub 后任何人都能用。

**改动**：
- `config.py` 中所有密钥的默认值改为空字符串 `""`
- 备用密钥只从环境变量 `DEEPSEEK_API_KEY_1`、`DEEPSEEK_API_KEY_2` 读取，删除硬编码 fallback
- PushPlus Token 默认值改为空
- PubMed 邮箱默认值改为空
- `.env.example` 补充所有需要的变量说明
- 启动时如果关键密钥为空，打印明确的错误提示并退出

**涉及文件**：`backend/core/config.py`、`.env.example`
**风险**：低。部署时需要确保 `.env` 文件已配置。

### 1.2 清理根目录残留文件
**问题**：根目录有 `项目文件清理计划.md`、`IMPLEMENTATION_SUMMARY.md`、`运行命令.txt`、`快速设置定时任务.txt`、`app/` 旧目录等，结构混乱。

**改动**：
- 删除 `IMPLEMENTATION_SUMMARY.md`（内容过时）
- `运行命令.txt` 内容合并到 `README.md`，然后删除
- `快速设置定时任务.txt` 内容合并到 `docs/README_定时任务设置.md`，然后删除
- `项目文件清理计划.md` 执行完后删除
- 确认 `app/` 目录是否还在使用，如果已迁移到 `backend/` 则删除

**涉及文件**：根目录多个文件
**风险**：低。

---

## 第二阶段：核心逻辑优化（直接影响推送质量）

### 2.1 拆分 `run_push_task` 函数
**问题**：`cli.py` 的 `run_push_task` 约 300 行，采集、筛选、生成、推送全部塞在一个函数里，难以调试和维护。

**改动**：拆分为独立函数
```
run_push_task()
├── fetch_papers()          # 数据采集（多源并发）
├── score_and_filter()      # 评分 + 快速AI筛选
├── generate_reports()      # 逐篇生成AI报告
├── build_daily_report()    # 组装最终报告（格式化、编号）
├── save_and_push()         # 保存文件 + 多渠道推送
└── mark_sent()             # 标记已推送论文
```

**涉及文件**：`backend/cli.py`
**风险**：中。需要确保拆分后逻辑一致，建议拆完跑一次完整流程验证。

### 2.2 EuropePMC 返回 0 篇排查
**问题**：日常运行中 EuropePMC 经常返回 0 篇，但项目设计就是只取前一天，不应改窗口。

**排查方向**：
1. 在本地手动调用 API，用当天日期测试查询是否有结果
2. 如果 API 本身确实返回 0，说明前一天该领域没有新发表——这是正常的，不需要修
3. 如果 API 有结果但代码拿不到，检查是否是代理/网络/URL编码问题
4. 增加日志：把完整的查询 URL 在 INFO 级别输出，方便排查

**改动**：在 `europepmc.py` 的 fetch 方法中，将查询 URL 日志从 DEBUG 提升到 INFO。

**涉及文件**：`backend/sources/europepmc.py`
**风险**：低。

### 2.3 减少不必要的 LLM 调用
**问题**：当前流程对每篇论文调用两次 LLM（快速筛选 + 正式报告），成本翻倍。

**优化方案**：
- 方案A（推荐）：去掉快速筛选，直接用评分系统过滤低分论文。评分系统已经有上下文检查，大部分不相关论文已经被低分淘汰了
- 方案B：合并两次调用为一次——在生成报告的 prompt 中加入"如果不相关请返回不相关标记"（当前已有此逻辑），去掉前置的快速筛选步骤

**涉及文件**：`backend/cli.py`、`backend/llm/quick_check.py`
**风险**：中。需要对比去掉快速筛选前后的实际推送质量。

---

## 第三阶段：代码质量改善

### 3.1 统一异常处理
**问题**：多处 bare `except` 或 `except Exception: pass`，吞掉了有用的错误信息。

**改动**：
- `scoring.py` 第 224 行日期解析的 `except Exception: pass` → 加 `logger.debug` 输出
- `github.py` 第 162 行 `except: pass` → `except (ValueError, TypeError): pass`
- 全局搜索 bare `except`，逐个检查是否有必要

**涉及文件**：多个文件
**风险**：低。

### 3.2 `.gitignore` 完善
**问题**：确保以下内容不会被提交：
- `.env` 文件
- `data/` 目录（数据库、缓存）
- `__pycache__/`
- 日志文件

**涉及文件**：`.gitignore`
**风险**：低。

### 3.3 添加关键路径的集成测试
**问题**：`tests/` 目录的测试和实际代码不匹配，没有覆盖核心流程。

**改动**：至少添加以下测试：
- `test_scoring.py`：用几篇真实论文标题/摘要测试评分逻辑，验证相关论文得高分、不相关论文得低分
- `test_report_format.py`：验证报告编号连续、格式层级正确
- 数据源测试用 mock，不依赖外网

**涉及文件**：`tests/` 目录
**风险**：低。

---

## 第四阶段：体验优化（锦上添花）

### 4.1 报告可读性改进
- 在报告头部添加简要统计：各数据源命中数、总检索数、最终推送数
- 相关论文按研究方向分组展示（固氮 / 信号转导 / 酶结构）

### 4.2 前端完善
- 查看历史推送报告
- 手动触发一次推送
- 查看各数据源的实时状态

### 4.3 配置热更新
- 通过前端修改关键词列表、排除词列表，不用改代码重启

---

## 不建议做的事

| 想法 | 为什么不做 |
|------|-----------|
| 添加 arXiv/medRxiv 数据源 | 三个方向很窄，现有源已够用，加源只会增加噪音和维护成本 |
| 用更贵的 LLM（GPT-4等） | DeepSeek 做摘要足够了，质量瓶颈在筛选不在总结 |
| 添加用户系统/多租户 | 个人工具，过度设计 |
| 论文全文下载分析 | API 成本高、版权问题、摘要已够用 |

---

## 执行建议

1. **先做 1.1**（清密钥），这是安全问题，10 分钟能搞定
2. **再做 2.2**（EuropePMC 排查），在本地跑一次看日志就知道原因
3. **然后做 2.1**（拆函数），这是后续所有改进的基础
4. 其余按需推进
